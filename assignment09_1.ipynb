{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 9.1 - Backpropagation\n",
    "\n",
    "Please submit your solution of this notebook in the Whiteboard at the corresponding Assignment entry as .ipynb-file and as .pdf. <br><br>\n",
    "Please do **NOT** rename the file!\n",
    "\n",
    "#### State both names of your group members here:\n",
    "[Jane and John Doe]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 9.1.1: Backpropagation\n",
    "\n",
    "* Implement a two-layer artificial neural network using `numpy` and/or `torch`with two input neurons and one output neuron. Choose the number of hidden neurons to your liking. **(RESULT)**\n",
    "* Implement a train function that runs the backpropagation algorithm. Don't use `PyTorch`'s autograd functionality. **(RESULT)**\n",
    "* Our goal is to learn the XOR function. What does the network return for random weights of all combinations of (binary) inputs? **(RESULT)**\n",
    "\n",
    "Further reading: Rojas book (https://www.inf.fu-berlin.de/inst/ag-ki/rojas_home/documents/1996/NeuralNetworks/neuron.pdf), chapter 7.3.3 and learn about the \"matrix way\" of implementing backprop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Helper functions\n",
    "def normalize(data, mean=None, variance=None, ret=False):\n",
    "    \"\"\"Normalizes the data to allow for faster convergence of the gradient ascent\"\"\"\n",
    "    if mean is None:\n",
    "        mean = np.mean(data, axis=0)[np.newaxis,:]\n",
    "    if variance is None:\n",
    "        std = np.std(data, axis=0)[np.newaxis,:]\n",
    "    std[np.where(std == 0)] = 1\n",
    "    data_ = (data - mean) / std\n",
    "    if ret:\n",
    "        return data_\n",
    "    else:\n",
    "        return data_, mean, std\n",
    "\n",
    "def onehot(labels, k):\n",
    "    n = len(labels)\n",
    "    onehot_labels = np.zeros([n, k])\n",
    "    onehot_labels[range(n), labels] = 1\n",
    "    return onehot_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN:   # Feel free to adjust the class structure / functions.\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        # TODO: Implement\n",
    "\n",
    "    def train(self):\n",
    "        pass\n",
    "        # TODO: Implement\n",
    "\n",
    "    def feedforward(self):\n",
    "        \"\"\"Feed-forward given input and weight matrices W1 and W2.\"\"\"\n",
    "        pass\n",
    "        # TODO: Implement\n",
    "\n",
    "    def backprop(self):\n",
    "        pass\n",
    "        # TODO: Implement\n",
    "\n",
    "    def optimize(self):\n",
    "        \"\"\"Update step\"\"\"\n",
    "        pass\n",
    "        # TODO: Implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XOR dataset\n",
    "xor_data = np.array([\n",
    "    [0,0],\n",
    "    [0,1],\n",
    "    [1,0],\n",
    "    [1,1],\n",
    "])\n",
    "xor_labels = onehot(np.array([0, 1, 1, 0]), 2)\n",
    "print(xor_labels.shape)\n",
    "print(xor_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 9.1.2: Backpropagation\n",
    "\n",
    "Implement Backpropagation and optimize the weights of your neural network using the XOR dataset: \n",
    "\n",
    "| x | y |\n",
    "| -------- | ------- |\n",
    "| (0,0) | 0 |\n",
    "| (0,1) | 1 |\n",
    "| (1,0) | 1 |\n",
    "| (1,1) | 0 |\n",
    "\n",
    "* How many training iterations do you need? Plot the network error over the number of iterations **(RESULT)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 9.1.3: MNIST (BONUS)\n",
    "\n",
    "* Train your network on the [MNIST dataset](http://yann.lecun.com/exdb/mnist/) and state the model accuracy (or the model error) for the training and test sets. **(RESULT)** \n",
    "* Compare to this [list](https://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#4d4e495354) and report on the performance of your model. **(RESULT)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can access MNIST using torchvision (https://pytorch.org/vision/main/generated/torchvision.datasets.MNIST.html)\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "mnist_train = datasets.MNIST(root='./data', train=True, download=True, transform=None)\n",
    "mnist_test = datasets.MNIST(root='./data', train=False, download=True, transform=None)\n",
    "\n",
    "mnist_train_data = mnist_train.data.numpy()\n",
    "mnist_train_labels = mnist_train.targets.numpy()\n",
    "mnist_test_data = mnist_test.data.numpy()\n",
    "mnist_test_labels = mnist_test.targets.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = mnist_train_data[:5], mnist_train_labels[:5]\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(20, 5))\n",
    "for i in range(5):\n",
    "    axes[i].set_title(labels[i])\n",
    "    axes[i].imshow(images[i], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train_data_, mean, mu = normalize(mnist_train_data.reshape([-1, 28*28]))\n",
    "mnist_train_labels_ = onehot(mnist_train_labels, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok-ish performance (error-rate 7%+), still a large gap to state-of-the-art models (error-rate 0.21%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratz, you made it! :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyforecast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
